---
layout: post
title: 《从头开始构建大语言模型》01
date: 2024-07-13
author: 曾伟
tags: [论文阅读]
comments: true
toc: true # 目录
# pinned: true 是否置顶
---

简介：人生迷茫的时候，就来读书学习吧。今天偶然在微信公众号[深度学习与NLP](https://mp.weixin.qq.com/s/S6qI0yGdIpu_H8RG-ZRwqw)上看到介绍一本新书[《Build a Large Language Model From Scratch》（从头开始构建大语言模型）]((https://github.com/rasbt/LLMs-from-scratch))，真羡慕老美总是能及时出这么好的书，目前好像还没对应的中文书。这本英文书在[MANNING](https://www.manning.com/books/build-a-large-language-model-from-scratch)卖31.19美刀，穷逼自然是不可能买的，继续搜索在[SCRIBD](https://www.scribd.com/document/736025575/Sebastian-Raschka-Build-a-Large-Language-Model-From-Scratch-Manning-Publications-Co-2024)网上找到[PDF](https://github.com/ZengWeiTHU/eBook/blob/main/LLM/Build-a-Large-Language-Model-From-Scratch.pdf)下载链接，随便在Arxiv上找了五篇论文上传下载得到，不过对比了一下目录发现不是最新版，不过还是可以凑活着读，另外发现中文互联网也有人已经开始阅读了，比如[Datawhale](https://github.com/datawhalechina/llms-from-scratch-cn)，[博客1](https://blog.buhe.dev/%E8%AF%BBbuild-a-large-language-model-from-scratch)，[博客2](https://blog.csdn.net/sxc1414749109/article/details/137950234)。稍等，最终我发现在[MANNING](https://www.manning.com/books/build-a-large-language-model-from-scratch)上可以按章阅读:sweat_smile:。

## 目录
首先是目录，我下载的这一版应该是旧版，它的目录是这样的：
1. welcome 欢迎
2. 1_Understanding_Large_Language_Models 理解大语言模型
3. 2_Working_with_Text_Data 使用文本数据
4. 3_Coding_Attention_Mechanisms 编码注意力机制
5. 4_Implementing_a_GPT_model_from_Scratch_To_Generate_Text 从头开始实现GPT模型以生成文本
6. 5_Pretraining_on_Unlabeled_Data 对未标记数据进行预训练
7. Appendix_A._Introduction_to_PyTorch 附录A:PyTorch简介
8. Appendix_B._References_and_Further_Reading 附录B:参考文献和进一步阅读
9. Appendix_C._Exercise_Solutions 附录C:习题参考答案
10. Appendix_D._Adding_Bells_and_Whistles_to_the_Training_Loop 附录D:在训练循环中添加附加功能

